{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgv98kwm5Vyr"
      },
      "source": [
        "# for local run\n",
        "## MLflow Integration for Model Training and Tracking\n",
        "\n",
        "In this notebook, we're integrating MLflow into a machine learning workflow to track and manage experiments effectively. We're focusing on a text classification task using the DistilBert model, emphasizing the importance of experiment tracking, model management, and operational efficiency - core themes of our course.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0X5uyaQ5Vyt"
      },
      "source": [
        "### Objective:\n",
        "\n",
        "- Dynamically set up and log parameters to MLflow\n",
        "- Understand the purpose and application of each step in the context of MLflow and MLOps principles\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuSiMFnc5Vyt"
      },
      "source": [
        "### Environment Setup\n",
        "\n",
        "Ensure all necessary libraries are installed and imported for our workflow.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zebzdop25Vyu"
      },
      "source": [
        "\n",
        "### Imports\n",
        "\n",
        "Import the necessary libraries, focusing on MLflow for tracking, PyTorch for model training, and Transformers for our NLP model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "p0eWzvXf5Vyu"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\sebas\\Documents\\projet\\mlops-introduction\\mlflow_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "# !pip install datasets\n",
        "import os\n",
        "import mlflow\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "from datasets import load_dataset\n",
        "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer, AdamW\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ix-cE3OS5Vyu"
      },
      "source": [
        "### Configuration Parameters as an Object\n",
        "\n",
        "By defining parameters as a dictionary, we can easily iterate through them when logging to MLflow. This method streamlines the process and adheres to best practices in code maintainability and scalability.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qZ3uT3ED5Vyv"
      },
      "outputs": [],
      "source": [
        "params = {\n",
        "    'model_name': 'distilbert-base-cased',\n",
        "    'learning_rate': 5e-5,\n",
        "    'batch_size': 16,\n",
        "    'num_epochs': 1,\n",
        "    'dataset_name': 'ag_news',\n",
        "    'task_name': 'sequence_classification_v2',\n",
        "    'log_steps': 100,\n",
        "    'max_seq_length': 128,\n",
        "    'output_dir': 'models/distilbert-base-uncased-ag_news',\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUuBiFwN5Vyv"
      },
      "source": [
        "\n",
        "### MLflow Setup\n",
        "\n",
        "Setting up MLflow is crucial for tracking our experiments, parameters, and results, allowing us to manage and compare different runs effectively - a practice that aligns with the MLOps goal of systematic and efficient model management."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PH8r6mhd5Vyv"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024/07/04 13:05:41 INFO mlflow.tracking.fluent: Experiment with name 'sequence_classification_v2' does not exist. Creating a new experiment.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Experiment: artifact_location='file:///C:/Users/sebas/Documents/projet/mlops-introduction/artifact_store/4', creation_time=1720091141832, experiment_id='4', last_update_time=1720091141832, lifecycle_stage='active', name='sequence_classification_v2', tags={}>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
        "mlflow.set_experiment(f\"{params['task_name']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miIwBdFE5Vyw"
      },
      "source": [
        "### Load and Preprocess Dataset\n",
        "\n",
        "We're using a well-known NLP dataset to ensure reproducibility and comparability. The preprocessing step is crucial for converting raw text into a format that our model can understand, highlighting the importance of data preparation in the ML pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "tSp0aciO5Vyw"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading readme: 100%|██████████| 8.07k/8.07k [00:00<00:00, 8.08MB/s]\n",
            "Downloading data: 100%|██████████| 18.6M/18.6M [00:02<00:00, 8.20MB/s]\n",
            "Downloading data: 100%|██████████| 1.23M/1.23M [00:00<00:00, 3.60MB/s]\n",
            "Generating train split: 100%|██████████| 120000/120000 [00:00<00:00, 338269.42 examples/s]\n",
            "Generating test split: 100%|██████████| 7600/7600 [00:00<00:00, 409147.87 examples/s]\n",
            "c:\\Users\\sebas\\Documents\\projet\\mlops-introduction\\mlflow_env\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\sebas\\.cache\\huggingface\\hub\\models--distilbert-base-cased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n",
            "Map: 100%|██████████| 20000/20000 [00:22<00:00, 875.08 examples/s]\n",
            "Map: 100%|██████████| 2000/2000 [00:02<00:00, 864.85 examples/s]\n"
          ]
        }
      ],
      "source": [
        "# Load dataset\n",
        "dataset = load_dataset(params['dataset_name'])#, params['task_name'])\n",
        "\n",
        "# load the tokenizer\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(params['model_name'])\n",
        "\n",
        "# define a function to tokenize the dataset\n",
        "def tokenize(batch):\n",
        "    return tokenizer(batch['text'], padding='max_length', truncation=True, max_length=params['max_seq_length'])\n",
        "\n",
        "# apply shuffle and select 20,000 samples to train and 2,000 to test\n",
        "train_dataset = dataset[\"train\"].shuffle().select(range(20_000)).map(tokenize, batched=True)\n",
        "test_dataset = dataset[\"test\"].shuffle().select(range(2_000)).map(tokenize, batched=True)\n",
        "\n",
        "# Set format for PyTorch and create data loaders\n",
        "train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "test_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "\n",
        "# create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=params['batch_size'], shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=params['batch_size'], shuffle=False)\n",
        "\n",
        "# get the labels\n",
        "labels = dataset[\"train\"].features['label'].names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0IWkrp85Vyw"
      },
      "source": [
        "\n",
        "### Model Initialization\n",
        "\n",
        "Initializing the model is a foundational step, showcasing the practical application of a pre-trained NLP model for a specific task - reflecting the course's focus on real-world applicability of machine learning models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "h_uVy4Xc5Vyw"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DistilBertForSequenceClassification(\n",
              "  (distilbert): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0-5): 6 x TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# model init\n",
        "model = DistilBertForSequenceClassification.from_pretrained(params['model_name'], num_labels=len(labels))\n",
        "\n",
        "# set the id2label\n",
        "model.config.id2label = {i: label for i, label in enumerate(labels)}\n",
        "params['id2label'] = model.config.id2label\n",
        "\n",
        "# set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2p9VqT_5Vyw"
      },
      "source": [
        "### Optimizer Setup\n",
        "\n",
        "Choosing the right optimizer and learning rate is vital for effective model training. It demonstrates the importance of hyperparameter tuning, a key concept in achieving optimal model performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "LKN9psfz5Vyw"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\sebas\\Documents\\projet\\mlops-introduction\\mlflow_env\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# set optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=params['learning_rate'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkqHGboA5Vyw"
      },
      "source": [
        "### Evaluation Function\n",
        "\n",
        "Evaluating the model on a separate test set helps us understand its performance on unseen data, highlighting the concept of generalization which is crucial for real-world applications."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "EasITvPx5Vyw"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, dataloader, device):\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    predictions, true_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            inputs, masks, labels = batch['input_ids'].to(device), batch['attention_mask'].to(device), batch['label'].to(device)\n",
        "\n",
        "            # Forward pass, calculate logit predictions\n",
        "            outputs = model(inputs, attention_mask=masks)\n",
        "            logits = outputs.logits\n",
        "            _, predicted_labels = torch.max(logits, dim=1)\n",
        "\n",
        "            predictions.extend(predicted_labels.cpu().numpy())\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Calculate Evaluation Metrics\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predictions, average='macro')\n",
        "\n",
        "    return accuracy, precision, recall, f1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aa0PjEfq5Vyx"
      },
      "source": [
        "### Training Loop\n",
        "\n",
        "The training loop is where the actual model training happens. Logging metrics and parameters at each step is crucial for tracking the model's progress, understanding its behavior, and making informed decisions - core aspects of the MLOps lifecycle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "B7EFQOe15Vyx"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [1/1] - (Loss: 0.290) - Steps: 100%|██████████| 1250/1250 [04:03<00:00,  5.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 Metrics: Accuracy: 0.9160, Precision: 0.9169, Recall: 0.9165, F1: 0.9161\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "2024/07/04 13:13:45 WARNING mlflow.utils.requirements_utils: Found torch version (2.3.1+cu118) contains a local version label (+cu118). MLflow logged a pip requirement for this package as 'torch==2.3.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
            "2024/07/04 13:14:31 WARNING mlflow.utils.requirements_utils: Found torch version (2.3.1+cu118) contains a local version label (+cu118). MLflow logged a pip requirement for this package as 'torch==2.3.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
            "Successfully registered model 'agnews-transformer-v2'.\n",
            "2024/07/04 13:14:32 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: agnews-transformer-v2, version 1\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished Training\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Created version '1' of model 'agnews-transformer-v2'.\n"
          ]
        }
      ],
      "source": [
        "# Start MLflow Run\n",
        "with mlflow.start_run(run_name=f\"{params['model_name']}-{params['dataset_name']}\") as run:\n",
        "\n",
        "    # Log all parameters at once\n",
        "    mlflow.log_params(params)\n",
        "\n",
        "    with tqdm(total=params['num_epochs'] * len(train_loader), desc=f\"Epoch [1/{params['num_epochs']}] - (Loss: N/A) - Steps\") as pbar:\n",
        "        for epoch in range(params['num_epochs']):\n",
        "            running_loss = 0.0\n",
        "            for i, batch in enumerate(train_loader, 0):\n",
        "                inputs, masks, labels = batch['input_ids'].to(device), batch['attention_mask'].to(device), batch['label'].to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(inputs, attention_mask=masks, labels=labels)\n",
        "                loss = outputs.loss\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                running_loss += loss.item()\n",
        "                if i and i % params['log_steps'] == 0:\n",
        "                    avg_loss = running_loss / params['log_steps']\n",
        "\n",
        "                    pbar.set_description(f\"Epoch [{epoch + 1}/{params['num_epochs']}] - (Loss: {avg_loss:.3f}) - Steps\")\n",
        "                    mlflow.log_metric(\"loss\", avg_loss, step=epoch * len(train_loader) + i)\n",
        "\n",
        "                    running_loss = 0.0\n",
        "                pbar.update(1)\n",
        "\n",
        "            # Evaluate Model\n",
        "            accuracy, precision, recall, f1 = evaluate_model(model, test_loader, device)\n",
        "            print(f\"Epoch {epoch + 1} Metrics: Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n",
        "\n",
        "            # Log metrics to MLflow\n",
        "            mlflow.log_metrics({'accuracy': accuracy, 'precision': precision, 'recall': recall, 'f1': f1}, step=epoch)\n",
        "\n",
        "\n",
        "    # Log model to MLflow through built-in PyTorch method\n",
        "    # mlflow.pytorch.log_model(model, \"model\")\n",
        "\n",
        "    # Log model to MLflow through custom method\n",
        "    os.makedirs(params['output_dir'], exist_ok=True)\n",
        "    model.save_pretrained(params['output_dir'])\n",
        "    tokenizer.save_pretrained(params['output_dir'])\n",
        "\n",
        "    mlflow.log_artifacts(params['output_dir'], artifact_path=\"model\")\n",
        "\n",
        "    # Log the model using PyTorch\n",
        "    mlflow.pytorch.log_model(model, \"model\")\n",
        "\n",
        "    model_uri = f\"runs:/{run.info.run_id}/model\"\n",
        "    mlflow.register_model(model_uri, \"agnews-transformer-v2\")\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Remote run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!modal run ../src/2_train_refactor.py"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "dev",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
